#!/usr/bin/env python
"""ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è©•ä¾¡æ–¹å¼ã®ãƒ†ã‚¹ãƒˆ"""

import asyncio
import sys
from pathlib import Path

# Import modules using installed package structure

from backend.app.services.scraper import NoteScraper
from backend.app.services.evaluator import ArticleEvaluator
from backend.app.utils.logger import setup_logger

logger = setup_logger("streaming_eval_test", console=True)


async def test_streaming_evaluation():
    """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è©•ä¾¡æ–¹å¼ã®ãƒ†ã‚¹ãƒˆ"""
    
    logger.info("=== ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è©•ä¾¡æ–¹å¼ãƒ†ã‚¹ãƒˆ ===")
    
    async with NoteScraper() as scraper:
        # Step 1: è¨˜äº‹ãƒªã‚¹ãƒˆå–å¾—
        logger.info("Step 1: è¨˜äº‹ãƒªã‚¹ãƒˆåé›†")
        article_list = await scraper.collect_article_list()
        
        if not article_list:
            logger.error("è¨˜äº‹ãƒªã‚¹ãƒˆãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        logger.info(f"å–å¾—ã—ãŸè¨˜äº‹æ•°: {len(article_list)}")
        
        # Step 2: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è©•ä¾¡ï¼ˆè¨˜äº‹è©³ç´°å–å¾—â†’å³è©•ä¾¡â†’ç ´æ£„ï¼‰
        logger.info("\nStep 2: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è©•ä¾¡é–‹å§‹")
        
        evaluator = ArticleEvaluator()
        total_articles = len(article_list)
        
        for i, ref in enumerate(article_list):
            logger.info(f"\n--- è¨˜äº‹ {i+1}/{total_articles} ---")
            logger.info(f"å‡¦ç†ä¸­: {ref['title']}")
            
            try:
                # è¨˜äº‹è©³ç´°å–å¾—ï¼ˆå…¨æ–‡å«ã‚€ï¼‰
                logger.info("ğŸ“„ è©³ç´°å–å¾—ä¸­...")
                article = await scraper.collect_article_with_details(
                    urlname=ref['urlname'],
                    key=ref['key']
                )
                
                if not article:
                    logger.error("âŒ è©³ç´°å–å¾—å¤±æ•—")
                    continue
                
                logger.info(f"âœ… è©³ç´°å–å¾—æˆåŠŸï¼ˆå…¨æ–‡: {len(article.content_full)} æ–‡å­—ï¼‰")
                
                # AIè©•ä¾¡å®Ÿè¡Œ
                logger.info("ğŸ¤– AIè©•ä¾¡ä¸­...")
                evaluation = await evaluator._evaluate_single_article(article)
                
                if evaluation:
                    logger.info(f"âœ… AIè©•ä¾¡æˆåŠŸ")
                    logger.info(f"   ç·åˆã‚¹ã‚³ã‚¢: {evaluation.total_score}/100")
                    logger.info(f"   æ–‡ç« ã®è³ª: {evaluation.quality_score}/40")
                    logger.info(f"   ç‹¬è‡ªæ€§: {evaluation.originality_score}/30")
                    logger.info(f"   ã‚¨ãƒ³ã‚¿ãƒ¡æ€§: {evaluation.entertainment_score}/30")
                    logger.info(f"   AIè¦ç´„: {evaluation.ai_summary[:100]}...")
                else:
                    logger.error("âŒ AIè©•ä¾¡å¤±æ•—")
                
                # è¨˜äº‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ç ´æ£„ï¼ˆãƒ¡ãƒ¢ãƒªç¯€ç´„ï¼‰
                del article
                logger.info("ğŸ—‘ï¸ è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ç ´æ£„ï¼ˆãƒ¡ãƒ¢ãƒªç¯€ç´„ï¼‰")
                
                # ãƒ¬ãƒ¼ãƒˆåˆ¶é™
                await asyncio.sleep(2)
                
            except Exception as e:
                logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        logger.info(f"\n=== ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è©•ä¾¡å®Œäº† ===")
        logger.info("ãƒ¡ãƒªãƒƒãƒˆ:")
        logger.info("- DBå®¹é‡åœ§è¿«ãªã—ï¼ˆå…¨æ–‡ä¿å­˜ã—ãªã„ï¼‰")
        logger.info("- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æœ€å°åŒ–")
        logger.info("- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è©•ä¾¡")


async def compare_data_sizes():
    """ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºæ¯”è¼ƒ"""
    logger.info("\n=== ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºæ¯”è¼ƒ ===")
    
    async with NoteScraper() as scraper:
        article_list = await scraper.collect_article_list()
        
        if not article_list:
            return
        
        ref = article_list[0]
        article = await scraper.collect_article_with_details(
            urlname=ref['urlname'],
            key=ref['key']
        )
        
        if article:
            preview_size = len(article.content_preview.encode('utf-8'))
            full_size = len(article.content_full.encode('utf-8'))
            
            logger.info(f"1è¨˜äº‹ã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º:")
            logger.info(f"  ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: {preview_size:,} bytes")
            logger.info(f"  å…¨æ–‡: {full_size:,} bytes")
            logger.info(f"  å·®åˆ†: {full_size - preview_size:,} bytes")
            
            # å¹´é–“æ¨å®š
            daily_articles = 100
            yearly_preview = preview_size * daily_articles * 365
            yearly_full = full_size * daily_articles * 365
            
            logger.info(f"\nå¹´é–“æ¨å®šï¼ˆ100è¨˜äº‹/æ—¥ï¼‰:")
            logger.info(f"  ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã¿: {yearly_preview:,} bytes ({yearly_preview/1024/1024:.1f} MB)")
            logger.info(f"  å…¨æ–‡ä¿å­˜: {yearly_full:,} bytes ({yearly_full/1024/1024:.1f} MB)")
            logger.info(f"  å·®åˆ†: {yearly_full - yearly_preview:,} bytes ({(yearly_full - yearly_preview)/1024/1024:.1f} MB)")


if __name__ == "__main__":
    asyncio.run(test_streaming_evaluation())
    asyncio.run(compare_data_sizes())